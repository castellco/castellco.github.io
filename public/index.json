


[{"content":"","date":"31 diciembre 2025","externalUrl":null,"permalink":"/","section":"","summary":"","title":"","type":"page"},{"content":"También puedes ver mi currículum más detallado en LinkedIn: https://www.linkedin.com/in/cornejocastellano\nExperiencia\rOrganización\rLink\rRol\rFechas\rLugar\rVestas\rConstruction Quality Deployment Lead\r2025 – Hoy\rMadrid, España\rWorld Vision\rAnalista Nacional de Manejo de la Información\r2024 – 2025\rLima, Perú\rVestas\rData Management Trainee\r2023\rMadrid, España\rConsorcio de Investigación Económica y Social\rGestora de Bases de Datos de Monitoreo y Evaluación\r2019 – 2021\rLima, Perú\rPontificia Universidad Católica del Perú\rAsistente de Investigación\r2018 – 2021\rLima, Perú\rFondazione l'Albero della Vita\rPasante\r2018\rLima, Perú\rEducación\rInstitución\rLink\rGrado\rFechas\rUniversidad Carlos III de Madrid\rMáster Universitario en Ciencias Sociales Computacionales\r2024\rPontificia Universidad Católica del Perú\rDiplomado en Ciencia de Datos para las Ciencias Sociales y la Gestión Pública\r2021-2022\rUniversidad ESAN\rDiplomado en Monitoreo y Evaluación de Programas y Proyectos\r2024\rPontificia Universidad Católica del Perú\rBachiller en Comunicación para el Desarrollo\r2021-2022\rPublicaciones\rPortada\rTítulo\rReferencia\rPublisher\rExploring terrorism in Peru: a spatial approach\rCornejo Castellano, C. (2023)\rUniversidad Carlos III de Madrid\rGuía para elaborar investigaciones periodísticas sobre trata de personas (supervisión editorial)\rFernández, L. (2021)\rConsorcio de Investigación Económica y Social\rViolencia de género ejercida en el ámbito familiar contra niños, niñas y adolescentes percibidos como parte de la población LGTBI\rHuaita Alegre, M., Chavez Granda, J.,Cornejo Castellano, G. \u0026 Saravia Pinazo, M. (2019)\rPoder Judicial del Perú\rLa ratificación de la CEDAW como hito en la lucha por los derechos de las mujeres en el Perú\rHuaita Alegre, M., \u0026 Cornejo Castellano, G.(2019).\rIus et Veritas\rIgualdad para construir democracia. Análisis de candidaturas LGTBI en los procesos electorales de 2006 a 2016\rAlza, Carlos, et.al. (2017).\rJurado Nacional de Elecciones y Observatorio de Políticas Públicas para la Diversidad Sexual (DISEX), PUCP\r","date":"26 diciembre 2025","externalUrl":null,"permalink":"/cv/","section":"","summary":"También puedes ver mi currículum más detallado en LinkedIn: https://www.linkedin.com/in/cornejocastellano\nExperiencia\rOrganización\rLink\rRol\rFechas\rLugar\rVestas\rConstruction Quality Deployment Lead\r2025 – Hoy\rMadrid, España\rWorld Vision\rAnalista Nacional de Manejo de la Información\r2024 – 2025\rLima, Perú\rVestas\rData Management Trainee\r2023\rMadrid, España\rConsorcio de Investigación Económica y Social\rGestora de Bases de Datos de Monitoreo y Evaluación\r2019 – 2021\rLima, Perú\rPontificia Universidad Católica del Perú\rAsistente de Investigación\r2018 – 2021\rLima, Perú\rFondazione l'Albero della Vita\rPasante\r2018\rLima, Perú\rEducación\rInstitución\rLink\rGrado\rFechas\rUniversidad Carlos III de Madrid\rMáster Universitario en Ciencias Sociales Computacionales\r2024\rPontificia Universidad Católica del Perú\rDiplomado en Ciencia de Datos para las Ciencias Sociales y la Gestión Pública\r2021-2022\rUniversidad ESAN\rDiplomado en Monitoreo y Evaluación de Programas y Proyectos\r2024\rPontificia Universidad Católica del Perú\rBachiller en Comunicación para el Desarrollo\r2021-2022\rPublicaciones\rPortada\rTítulo\rReferencia\rPublisher\rExploring terrorism in Peru: a spatial approach\rCornejo Castellano, C. (2023)\rUniversidad Carlos III de Madrid\rGuía para elaborar investigaciones periodísticas sobre trata de personas (supervisión editorial)\rFernández, L. (2021)\rConsorcio de Investigación Económica y Social\rViolencia de género ejercida en el ámbito familiar contra niños, niñas y adolescentes percibidos como parte de la población LGTBI\rHuaita Alegre, M., Chavez Granda, J.,Cornejo Castellano, G. \u0026 Saravia Pinazo, M. (2019)\rPoder Judicial del Perú\rLa ratificación de la CEDAW como hito en la lucha por los derechos de las mujeres en el Perú\rHuaita Alegre, M., \u0026 Cornejo Castellano, G.(2019).\rIus et Veritas\rIgualdad para construir democracia. Análisis de candidaturas LGTBI en los procesos electorales de 2006 a 2016\rAlza, Carlos, et.al. (2017).\rJurado Nacional de Elecciones y Observatorio de Políticas Públicas para la Diversidad Sexual (DISEX), PUCP\r","title":"CV","type":"page"},{"content":"","date":"20 mayo 2025","externalUrl":null,"permalink":"/tags/dataviz/","section":"Tags","summary":"","title":"Dataviz","type":"tags"},{"content":"","date":"20 mayo 2025","externalUrl":null,"permalink":"/tags/ggplot/","section":"Tags","summary":"","title":"Ggplot","type":"tags"},{"content":"","date":"20 mayo 2025","externalUrl":null,"permalink":"/tags/r/","section":"Tags","summary":"","title":"R","type":"tags"},{"content":"","date":"20 mayo 2025","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"\rIntroducción\r#\rLos bump charts son una herramienta poderosa en visualización de datos que permite mostrar cambios en rankings entre diferentes categorías o grupos. Aquí documentaré cómo repliqué un bump chart profesional creado en Tableau y publicado originalmente en Visual Capitalist, usando R y ggplot2.\nEste es el gráfico original (interactivo) que replicaremos en R, estático: Su objetivo es visualizar cómo diferentes generaciones de estadounidenses distribuyen sus gastos en 14 categorías, desde la generación Silent (nacidos en 1945 o antes) hasta la Generación Z (nacidos en 1997 o después). El análisis se basa en datos de la Consumer Expenditure Survey del U.S. Bureau of Labor Statistics de 2021.\n¿Qué es un bump chart?\r#\rUn bump chart es un tipo especializado de gráfico de líneas que enfatiza cambios de posición o ranking en lugar de valores absolutos. A diferencia de los gráficos de líneas tradicionales, el eje Y representa posiciones ordinales (1º, 2º, 3º\u0026hellip;) en lugar de valores continuos.\nCasos de uso ideales\r#\rLos bump charts son especialmente útiles para:\nVisualizar competencia: Mostrar cómo cambian las posiciones relativas entre competidores a lo largo del tiempo Analizar rankings: Seguir el rendimiento de categorías en clasificaciones (deportes, ventas, preferencias) Comparar prioridades: Entender qué es más o menos importante para diferentes grupos Detectar patrones: Identificar tendencias de ascenso, descenso o estabilidad en las posiciones En nuestro caso, el bump chart revela qué categorías de gasto son prioritarias (tienen mayor ranking) para cada generación.\nContexto del gráfico original\r#\rEl gráfico original fue creado por Preethi Lodha y publicado en Visual Capitalist en septiembre de 2022. Utiliza Tableau para crear una visualización interactiva, pero en este tutorial replicaremos la versión estática usando únicamente R.\nLos datos provienen de la tabla 2602 del Bureau of Labor Statistics: \u0026ldquo;Generation of reference person: Annual expenditure means, shares, standard errors, and coefficients of variation\u0026rdquo; del año 2021.\nPreparación del entorno\r#\rInstalación de paquetes\r#\rPrimero, hay que instalar los paquetes necesarios:\n# Instalar paquetes si no los tienes install.packages(c(\u0026#34;tidyverse\u0026#34;, \u0026#34;ggplot2\u0026#34;, \u0026#34;ggtext\u0026#34;, \u0026#34;grid\u0026#34;))\rCargar librerías\r#\r# Cargar librerías necesarias library(tidyverse) # Manipulación de datos library(ggplot2) # Creación de gráficos library(ggtext) # Renderizado de texto HTML/Markdown library(grid) # Elementos gráficos adicionales\rImportación y preparación de datos\r#\rCargar los datos\r#\rLos datos están disponibles en formato CSV en mi repositorio de GitHub:\n# Importar datos desde GitHub df \u0026lt;- read_csv(\u0026#34;https://github.com/castellco/bump-chart/raw/main/data.csv\u0026#34;) # Visualizar las primeras filas head(df)\rLa estructura original contiene una fila por generación y una columna por categoría de gasto:\n# A tibble: 5 × 15 generation housing healthcare food transportation cash_contributions \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; 1 silent 16656 7053 5487 5263 4045 2 boomers 21273 6594 7651 9327 2876 3 gen_X 26385 5550 10388 13956 2747 4 millennials 24052 4026 8463 11052 1163 5 gen_Z 15449 1354 5529 7929 760\rTransformar a formato long\r#\rPara crear un bump chart, necesitamos transformar los datos de formato \u0026ldquo;wide\u0026rdquo; a \u0026ldquo;long\u0026rdquo;, donde cada fila representa una combinación de generación y categoría de gasto:\n# Pivotar a formato long y calcular rankings df \u0026lt;- df %\u0026gt;% # Convertir de wide a long pivot_longer(-generation, names_to = \u0026#34;variables\u0026#34;, values_to = \u0026#34;dollars\u0026#34;) %\u0026gt;% # Agrupar por generación group_by(generation) %\u0026gt;% # Ordenar por monto gastado (descendente) arrange(generation, desc(dollars)) %\u0026gt;% # Asignar ranking dentro de cada generación mutate(ranking = row_number()) %\u0026gt;% ungroup()\rRenombrar categorías para mejor legibilidad\r#\r# Renombrar generaciones df$generation[df$generation == \u0026#34;silent\u0026#34;] \u0026lt;- \u0026#34;Silent\u0026#34; df$generation[df$generation == \u0026#34;boomers\u0026#34;] \u0026lt;- \u0026#34;Boomers\u0026#34; df$generation[df$generation == \u0026#34;gen_X\u0026#34;] \u0026lt;- \u0026#34;Generation X\u0026#34; df$generation[df$generation == \u0026#34;millennials\u0026#34;] \u0026lt;- \u0026#34;Millennials\u0026#34; df$generation[df$generation == \u0026#34;gen_Z\u0026#34;] \u0026lt;- \u0026#34;Generation Z\u0026#34; # Renombrar categorías de gasto con nombres completos df$variables[df$variables == \u0026#34;alcohol\u0026#34;] \u0026lt;- \u0026#34;Alcoholic beverages\u0026#34; df$variables[df$variables == \u0026#34;apparel\u0026#34;] \u0026lt;- \u0026#34;Apparel and services\u0026#34; df$variables[df$variables == \u0026#34;cash_contributions\u0026#34;] \u0026lt;- \u0026#34;Cash contributions\u0026#34; df$variables[df$variables == \u0026#34;education\u0026#34;] \u0026lt;- \u0026#34;Education\u0026#34; df$variables[df$variables == \u0026#34;entertainment\u0026#34;] \u0026lt;- \u0026#34;Entertainment\u0026#34; df$variables[df$variables == \u0026#34;food\u0026#34;] \u0026lt;- \u0026#34;Food\u0026#34; df$variables[df$variables == \u0026#34;healthcare\u0026#34;] \u0026lt;- \u0026#34;Healthcare\u0026#34; df$variables[df$variables == \u0026#34;housing\u0026#34;] \u0026lt;- \u0026#34;Housing\u0026#34; df$variables[df$variables == \u0026#34;insurance\u0026#34;] \u0026lt;- \u0026#34;Personal insurance and pensions\u0026#34; df$variables[df$variables == \u0026#34;miscellaneous\u0026#34;] \u0026lt;- \u0026#34;Miscellaneous expenditures\u0026#34; df$variables[df$variables == \u0026#34;personal_care\u0026#34;] \u0026lt;- \u0026#34;Personal care products and services\u0026#34; df$variables[df$variables == \u0026#34;reading\u0026#34;] \u0026lt;- \u0026#34;Reading\u0026#34; df$variables[df$variables == \u0026#34;smoking\u0026#34;] \u0026lt;- \u0026#34;Tobacco products and smoking \\n supplies\u0026#34; df$variables[df$variables == \u0026#34;transportation\u0026#34;] \u0026lt;- \u0026#34;Transportation\u0026#34;\rFormatear valores monetarios\r#\r# Formatear la columna de dólares para mostrar con separador de miles df$dollars \u0026lt;- format(df$dollars, big.mark = \u0026#34;,\u0026#34;, trim = TRUE) df$dollars \u0026lt;- paste0(\u0026#34;$\u0026#34;, df$dollars)\rDiseño de etiquetas enriquecidas\r#\rUna característica distintiva de este bump chart es el uso de etiquetas enriquecidas con HTML que muestran múltiples niveles de información en el eje X.\nCrear vectores de etiquetas\r#\r# Orden cronológico de las generaciones x_names_ordered \u0026lt;- c(\u0026#34;Silent\u0026#34;, \u0026#34;Boomers\u0026#34;, \u0026#34;Generation X\u0026#34;, \u0026#34;Millennials\u0026#34;, \u0026#34;Generation Z\u0026#34;) # Etiquetas enriquecidas con HTML x_names_full \u0026lt;- c( paste(\u0026#34;\u0026lt;span style=\u0026#39;font-size: 9.55pt\u0026#39;\u0026gt;**Silent**\u0026lt;/span\u0026gt;\u0026#34;, \u0026#34;1945 or earlier\u0026#34;, \u0026#34;**$44,683**\u0026#34;, sep = \u0026#34;\u0026lt;br\u0026gt;\u0026#34;), paste(\u0026#34;\u0026lt;span style=\u0026#39;font-size: 9.55pt\u0026#39;\u0026gt;**Boomers**\u0026lt;/span\u0026gt;\u0026#34;, \u0026#34;1946 to 1964\u0026#34;, \u0026#34;**$62,203**\u0026#34;, sep = \u0026#34;\u0026lt;br\u0026gt;\u0026#34;), paste(\u0026#34;\u0026lt;span style=\u0026#39;font-size: 9.55pt\u0026#39;\u0026gt;**Generation X**\u0026lt;/span\u0026gt;\u0026#34;, \u0026#34;1965 to 1980\u0026#34;, \u0026#34;**$83,357**\u0026#34;, sep = \u0026#34;\u0026lt;br\u0026gt;\u0026#34;), paste(\u0026#34;\u0026lt;span style=\u0026#39;font-size: 9.55pt\u0026#39;\u0026gt;**Millennials**\u0026lt;/span\u0026gt;\u0026#34;, \u0026#34;1981 to 1996\u0026#34;, \u0026#34;**$69,061**\u0026#34;, sep = \u0026#34;\u0026lt;br\u0026gt;\u0026#34;), paste(\u0026#34;\u0026lt;span style=\u0026#39;font-size: 9.55pt\u0026#39;\u0026gt;**Generation Z**\u0026lt;/span\u0026gt;\u0026#34;, \u0026#34;1997 or later\u0026#34;, \u0026#34;**$41,636**\u0026#34;, sep = \u0026#34;\u0026lt;br\u0026gt;\u0026#34;) ) # Etiqueta para el eje X completo x_lab \u0026lt;- paste( \u0026#34;\u0026lt;span style=\u0026#39;font-size: 10pt\u0026#39;\u0026gt;**Generation**\u0026lt;/span\u0026gt;\u0026#34;, \u0026#34;Birth Year Range\u0026#34;, \u0026#34;**Average Annual Expenditure**\u0026#34;, sep = \u0026#34;\u0026lt;br\u0026gt;\u0026#34; )\rEstas etiquetas proporcionan tres niveles de información:\nNombre de la generación (en negrita) Rango de años de nacimiento Gasto anual promedio total (en negrita) Construcción del tema personalizado\r#\rUn tema visual coherente es fundamental para la efectividad del bump chart. Vamos a crear theme_bump() que define todos los aspectos estéticos del gráfico. Si bien es posible usar temas predefinidos como theme_minimal() o theme_classic(), crear un tema personalizado permite controlar cada detalle, que es lo que necesitamos para replicar fielmente el diseño original.\nDefinir colores\r#\r# Paleta de colores color_background \u0026lt;- \u0026#34;#e5d9cf\u0026#34; # Fondo cálido color_text \u0026lt;- \u0026#34;#333333\u0026#34; # Texto oscuro\rCrear el tema\r#\rtheme_bump \u0026lt;- function() { theme_bw(base_size = 15) + # Fondos theme(panel.background = element_rect(fill = color_background, color = color_background)) + theme(plot.background = element_rect(fill = color_background, color = color_background)) + theme(panel.border = element_rect(color = color_background)) + theme(strip.background = element_rect(fill = color_background, color = color_background)) + # Cuadrícula theme(axis.ticks = element_blank()) + theme(panel.grid = element_line(colour = color_background)) + # Leyenda (no se muestra) theme(legend.position = \u0026#34;none\u0026#34;) + # Caption theme(plot.caption = element_text(hjust = 0.6, vjust = 0.1, size = 5.45)) + # Títulos theme(plot.title = element_text(color = color_text, size = 17.5, face = \u0026#34;bold\u0026#34;, hjust = 0.5, margin = margin(0,0,10,0))) + theme(plot.subtitle = element_text(color = color_text, size = 11, hjust = 0.5, face = \u0026#34;bold\u0026#34;, margin = margin(0,0,22,0))) + # Ejes theme(axis.title.x = element_blank()) + theme(axis.title.y = element_blank()) + theme(axis.text = element_markdown()) + theme(axis.text.x.top = element_markdown(color = \u0026#34;#3b3b3a\u0026#34;, family = \u0026#34;Arial Narrow\u0026#34;, size = 7.5)) + theme(axis.text.y = element_blank()) + # Tag (etiqueta adicional) theme(plot.tag = element_markdown(family = \u0026#34;Arial Narrow\u0026#34;, lineheight = 0.1, size = 8)) + theme(plot.tag.position = c(0.10, 0.85)) + # Márgenes theme(plot.margin = unit(c(0.5, 0.4, 0.5, 0.65), \u0026#34;cm\u0026#34;)) }\rConstrucción del bump chart\r#\rAhora viene la parte más importante: ensamblar todos los elementos para crear el bump chart.\nreplica \u0026lt;- ggplot( data = df, aes(x = generation, y = ranking, group = variables)) + # Aplicar tema personalizado theme_bump() + # Líneas conectando los puntos (grosor varía según ranking) geom_line(aes(color = variables, alpha = 1, linewidth = rev(ranking))) + # Puntos con borde blanco geom_point(size = 11.85, color = \u0026#34;white\u0026#34;) + geom_point(aes(color = variables), size = 11.3) + # Invertir eje Y (ranking 1 arriba) scale_y_reverse(breaks = 1:nrow(df)) + # Configurar eje X con etiquetas enriquecidas scale_x_discrete( limits = x_names_ordered, labels = x_names_full, position = \u0026#34;top\u0026#34;, expand = expansion(mult = c(0.356, 0.1)) ) + # Títulos y caption labs( title = \u0026#34;HOW AMERICANS SPEND THEIR MONEY\u0026#34;, subtitle = \u0026#34;By Age Group | 2021\u0026#34;, caption = \u0026#34;Author: Preethi Lodha\u0026#34;, tag = x_lab ) + # Permitir elementos fuera del área de trazado coord_cartesian(clip = \u0026#34;off\u0026#34;) + # Líneas horizontales blancas superior e inferior annotation_custom(linesGrob(x = c(0, 0.99), y = c(1.11, 1.11), gp = gpar(col = \u0026#34;#f0eae8\u0026#34;, lwd = 2.8, lineend = \u0026#34;square\u0026#34;))) + annotation_custom(linesGrob(x = c(0, 0.99), y = c(-0.05, -0.05), gp = gpar(col = \u0026#34;#f0eae8\u0026#34;, lwd = 2.8, lineend = \u0026#34;square\u0026#34;))) + # Etiquetas de categorías en el eje Y geom_text(data = df %\u0026gt;% filter(generation == \u0026#34;Silent\u0026#34;), aes(label = variables, x = 0.72236), hjust = \u0026#34;outward\u0026#34;, fontface = \u0026#34;bold\u0026#34;, color = \u0026#34;#272727\u0026#34;, size = 2.4) + # Montos gastados dentro de los puntos geom_text(aes(label = dollars), hjust = \u0026#34;center\u0026#34;, color = \u0026#34;white\u0026#34;, size = 2.25, fontface = \u0026#34;bold\u0026#34;) + # Paleta de colores personalizada scale_color_manual(values = c( \u0026#34;#9c6255\u0026#34;, \u0026#34;#a0d4ee\u0026#34;, \u0026#34;#9d8379\u0026#34;, \u0026#34;#8f93b5\u0026#34;, \u0026#34;#494c4d\u0026#34;, \u0026#34;#2f634a\u0026#34;, \u0026#34;#ed444a\u0026#34;, \u0026#34;#8a8887\u0026#34;, \u0026#34;#a13b5d\u0026#34;, \u0026#34;#87a7a0\u0026#34;, \u0026#34;#af9e2e\u0026#34;, \u0026#34;#6d1f29\u0026#34;, \u0026#34;#466f9d\u0026#34;, \u0026#34;#3896c4\u0026#34; )) # Mostrar el gráfico replica\rGuardar el gráfico\r#\rPara exportar el gráfico en alta calidad:\nggsave(\u0026#34;bump_chart_replica.png\u0026#34;, plot = replica, width = 8.29, height = 6.88, units = \u0026#34;in\u0026#34;, dpi = 300) # Alta resolución\rComparación con el original\r#\rEste es el gráfico original publicado en the Visual Capitalist, en Tableau: Esta es mi réplica en R, con ggplot2: Como se puede ver, la réplica captura fielmente todos los elementos visuales del original, excepto los componentes interactivos (que no son necesarios para la versión estática). Los elementos clave replicados incluyen:\nLíneas de grosor variable según el ranking Puntos con borde blanco para mejor visibilidad Etiquetas enriquecidas con múltiples niveles de información Paleta de colores distintiva para cada categoría Diseño limpio con fondo cálido Cantidades monetarias dentro de cada punto Insights del gráfico\r#\rDel bump chart podemos extraer varios hallazgos interesantes sobre los patrones de gasto generacional:\nHousing domina universalmente: La vivienda es el mayor gasto para todas las generaciones, ocupando consistentemente el primer lugar.\nTransportation mantiene alta prioridad: El transporte se posiciona en los primeros lugares, especialmente para Generation X y Millennials en sus años de mayor actividad laboral.\nHealthcare aumenta con la edad: Los gastos en salud muestran una trayectoria ascendente dramática para generaciones mayores (Silent y Boomers).\nEducation es prioritaria para jóvenes: Las generaciones más jóvenes (Gen Z y Millennials) priorizan más la educación, reflejando posiblemente el aumento de costos universitarios.\nPatrones de convergencia y divergencia: Mientras categorías básicas como \u0026ldquo;Food\u0026rdquo; mantienen posiciones estables, gastos discrecionales como \u0026ldquo;Entertainment\u0026rdquo; varían considerablemente entre generaciones.\nConsideraciones técnicas importantes\r#\rManejo del grosor de línea\r#\rEl código usa linewidth = rev(ranking) para variar el grosor de las líneas según el ranking. Esto proporciona una señal visual adicional sobre la importancia relativa de cada categoría, aunque su efecto es sutil.\nPosicionamiento de etiquetas\r#\rLas etiquetas de categorías se posicionan usando:\ngeom_text(data = df %\u0026gt;% filter(generation == \u0026#34;Silent\u0026#34;), aes(label = variables, x = 0.72236))\rEl valor 0.72236 fue ajustado manualmente para lograr el alineamiento perfecto. Este tipo de ajustes finos son comunes al crear visualizaciones personalizadas.\nMúltiples capas de texto\r#\rEl código incluye tres llamadas casi idénticas a geom_text() para los montos:\ngeom_text(aes(label = dollars), ..., size = 2.25, ...) + geom_text(aes(label = dollars), ..., size = 2.253, ...) + geom_text(aes(label = dollars), ..., size = 2.257, ...)\rEsta técnica crea un efecto de negrita más pronunciado mediante la superposición ligera de texto con tamaños incrementales.\nCódigo completo y reproducibilidad\r#\rEl código completo y los datos están disponibles en mi repositorio de GitHub:\nRepositorio: https://github.com/castellco/bump-chart castellco/bump-chart\rnull\r0\r0\rProyecto original: https://csslab.uc3m.es/dataviz/projects/2022/100481925/ Referencias\r#\rFuentes de datos\r#\rU.S. Bureau of Labor Statistics. (2022). Consumer Expenditure Survey, 2021. Recuperado de https://www.bls.gov/cex/\nGráfico original\r#\rLodha, P. (2022). How Do Americans Spend Their Money, By Generation? Visual Capitalist. https://www.visualcapitalist.com/cp/how-americans-spend-their-money-2022/\nDocumentación técnica (proyecto original)\r#\rWickham, H. (2016). ggplot2: Elegant Graphics for Data Analysis (2nd ed.). Springer-Verlag New York. https://ggplot2.tidyverse.org\nWickham, H., François, R., Henry, L., Müller, K., \u0026amp; Vaughan, D. (2023). dplyr: A Grammar of Data Manipulation. R package version 1.1.0. https://CRAN.R-project.org/package=dplyr\nWilke, C. O. (2023). ggtext: Improved Text Rendering Support for \u0026lsquo;ggplot2\u0026rsquo;. R package version 0.1.2. https://CRAN.R-project.org/package=ggtext\nMaterial del proyecto\r#\rCornejo Castellano, C. (2023). Bump chart: How Americans spend their money. UC3M Data Visualization Projects. https://csslab.uc3m.es/dataviz/projects/2022/100481925/\nCornejo Castellano, C. (2025). Bump Chart Tutorial - GitHub Repository. https://github.com/castellco/bump-chart\n","date":"20 mayo 2025","externalUrl":null,"permalink":"/posts/how-americans-spend-their-money/","section":"Posts","summary":"Aprende a crear bump charts profesionales en R usando ggplot2. Tutorial completo con código reproducible para visualizar rankings y cambios de posición entre categorías.","title":"Visualizar rankings en R: cómo crear bump charts con ggplot2","type":"posts"},{"content":"","date":"13 marzo 2025","externalUrl":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"","date":"7 febrero 2025","externalUrl":null,"permalink":"/tags/datos-espaciales/","section":"Tags","summary":"","title":"Datos Espaciales","type":"tags"},{"content":"","date":"7 febrero 2025","externalUrl":null,"permalink":"/tags/gis/","section":"Tags","summary":"","title":"GIS","type":"tags"},{"content":"Este post es sobre el TFM con el que me gradué del Máster Universitario en Ciencias Sociales Computacionales en la UC3M. Para este, apliqué modelos espaciales para estudiar la difusión de ataques terroristas en Perú durante la temporada álgida del Conflicto Armado Interno (1980-2000) y desde entonces a la actualidad, comparando diferentes períodos temporales y técnicas de modelado.\nEl código es open source en Github: castellco/terrorism_peru\rReplication files for \u0026ldquo;Exploring terrorism in Peru: A spatial approach\u0026rdquo;, thesis for the Master\u0026rsquo;s degree in Computational Social Science at UC3M.\rnull\r0\r0\r¿Por qué modelos espaciales? El problema de la dependencia espacial\r#\rLos métodos tradicionales de regresión (OLS) asumen que las observaciones son independientes entre sí. Sin embargo, en fenómenos espaciales como los ataques terroristas, esta suposición se viola sistemáticamente.\n“Todo está relacionado con todo lo demás, pero las cosas cercanas están más relacionadas que las distantes.”\n— Waldo Tobler (1970)\nEsta, la llamada \u0026ldquo;Primera ley de Tobler\u0026rdquo;, es la madre de varios conceptos clave en análisis espacial. En específico, en mi TFM refiero mucho a la autocorrelación espacial, que describe cómo las observaciones en ubicaciones geográficas cercanas tienden a ser más similares entre sí que las distantes. Ignorar esta dependencia lleva a estimaciones sesgadas de los efectos, errores estándar incorrectos (generalmente subestimados), e inferencias inválidas. Por eso, si quería estudiar la territorialidad del Conflicto Armado Interno, debían usar modelos espaciales.\nMetodología\r#\rSiguiendo las recomendaciones de Buhaug y Rød (2006), utilicé celdas de grilla (grid cells), en este caso de 0.5 × 0.5 grados decimales como unidades de análisis en lugar de divisiones administrativas tradicionales, como distritos o provincias.\nEste enfoque tiene ventajas, como que las celdas no cambian en tamaño, forma o número a lo largo del tiempo, permiten controlar mejor por decisiones políticas que podrían afectar la frecuencia de eventos, constituyen entidades inherentemente apolíticas (Tollefsen et al., 2012), entre otros.\nLos datos\r#\rIntegré datos de múltiples fuentes georreferenciadas:\nGlobal Terrorism Database (GTD): Mi principal dataset, que contiene información de ~200,000 incidentes terroristas a nivel global (1970-2021) PRIO-GRID: Una base de variables geodemográficas a nivel de celda 0.5×0.5 xSUB: Datos subnacionales de conflicto compatibles con PRIO-GRID Shapefiles: Geometrías de celdas mundiales y fronteras de Perú El procesamiento\r#\rBásicamente, y para resumir, hice un point-in-polygon spatial join para asignar los ataques (los puntos) a los grid cells (los polígonos). Luego, construí tres sub datasets temporales: uno para el pico de la violencia (1980-2000), otro para el declive (2001-2021), y otro para el período completo (1980-2021).\nLas variables\r#\rMi variable dependiente fue el número de ataques terroristas por celda. Estos son datos de conteo zero-inflated, ya que muchas celdas no registran ataques.\nComo variables independientes, seleccioné un conjunto basado en la literatura previa sobre geografía del conflicto armado (Buhaug y Rød, 2006; Weidmann, 2015; Hendrix y Salehyan, 2012), y por disposición de datos. En el código estos se identifican como:\nDist to borders: Distancia al borde territorial (km) Dist to capital: Distancia a Lima (km) Coca cultiv.: Presencia de cultivo de coca a gran escala (dummy) Ethnic groups: Presencia de grupos étnicos excluidos Avg elevation: Elevación promedio (metros) Open land prop.: Proporción de terreno abierto No of local langs: Número de lenguas locales Test de Moran\u0026rsquo;s I\r#\rEl I de Moran es el estadístico más utilizado para medir autocorrelación espacial global. Varía de -1 indicando dispersión perfecta, a +1 sugiriendo un agrupamiento perfecto.\nEl código en R es reproducible y, para resumir, utilicé la función moran.test() del paquete spdep. El resultado fue que la autocorrelación espacial es significativamente más pronunciada durante el período de declive (I = 0.268) que durante el pico de violencia (I = 0.032). Es decir, los ataques se concentraron geográficamente durante el declive.\nEsto se explica con que durante el período de repliegue de las fuerzas subversivas (2001-2021), los ataques se concentraron cada vez más en áreas específicas (principalmente VRAEM), creando un patrón de clustering espacial más fuerte.\nLos modelos espaciales: SAR y SEM\r#\rPara modelar la dependencia espacial, corrí un Spatial Error Model (SEM) y un Spatial Autoregressive Model (SAR).\nSegún Fischer y Wang (2011), hay dos formas principales de modelar la dependencia espacial: a través del término de error (spatial error) o a través de la variable dependiente (spatial lag). Usé SEM para probar si los errores estaban correlacionados espacialmente. Grosso modo, la lógica de este algoritmo es que si el modelo se equivoca al predecir en una celda, probablemente también se equivocará de forma similar en las celdas vecinas. Por otro lado, los SAR incluyen explícitamente el valor de la variable dependiente en las celdas vecinas como un predictor adicional.\nOtro punto importante es la definición de \u0026ldquo;vecino\u0026rdquo; o *neighbor\u0026quot; usada: Utilicé la definición tipo \u0026ldquo;Queen\u0026rdquo;: dos celdas son vecinas si comparten un borde o incluso solo una esquina.\nTambién apliqué modelos no espaciales (lineales y de conteo) como regresiones lineales, Negative Binominal y Zero-inflated Poisson, pero no profundizaré en ellos. Cabe resaltar que el objetivo de emplear diversos modelos no era identificar el \u0026ldquo;mejor\u0026rdquo;, sino evaluar la variabilidad en los efectos estimados de las variables explicativas: explicar los fenómenos más que predecir el resultado.\nConclusiones\r#\rLo primero: que la concentración geográfica de la violencia cambia dramáticamente a lo largo del conflicto: El I de Moran aumentó de 0.032 (pico) a 0.268 (declive), revelando que la violencia se volvió más espacialmente concentrada en el periodo 2001-2021.\nAdemás, durante el declive, los modelos SEM/SAR mostraron mejor ajuste que el OLS, y el parámetro espacial (λ = 0.467, ρ = 0.455) fue altamente significativo.\nPor otro lado, también encontré que los efectos de algunas variables son condicionales al período temporal. Variables clave como el cultivo de hoja de coca y la distancia a los bordes invierten su signo entre períodos, demostrando que analizar todo el conflicto como un bloque homogéneo oculta dinámicas críticas.\nPara finalizar, todo el análisis es completamente reproducible:\nRepositorio GitHub: github.com/castellco/terrorism_peru Archivo R Markdown: carolina_cornejo_tfm.Rmd (el código completo) Datasets: Carpeta /data/data.zip Shapefiles: Carpeta /shapefiles/ Figuras: Carpeta /figs/ Referencias\r#\rAnselin, L. (1988). Spatial Econometrics: Methods and Models. Springer.\nBuhaug, H., \u0026amp; Rød, J. K. (2006). Local determinants of African civil wars,\n","date":"7 febrero 2025","externalUrl":null,"permalink":"/posts/geografia-terrorismo-peru/","section":"Posts","summary":"Análisis espacial de incidentes y patrones de violencia en Perú usando datos públicos.","title":"La geografía del terrorismo","type":"posts"},{"content":"","date":"7 febrero 2025","externalUrl":null,"permalink":"/tags/per%C3%BA/","section":"Tags","summary":"","title":"Perú","type":"tags"},{"content":"Mi carrera comenzó en Perú, en investigación académica y proyectos de desarrollo, trabajando con personas y organizaciones que buscaban generar cambio real. Fue ahí donde descubrí que el problema rara vez era la falta de datos, sino saber cómo convertirlos en información y conocimiento.\nEsa inquietud me motivó a complementar mi perfil profesional: decidí especializarme en análisis y ciencia de datos porque quería y quiero construir ese puente entre los datos y las decisiones que realmente importan; y ayudar a que la evidencia rigurosa guíe acciones que comulguen con mis propósitos personales.\nActualmente trabajo desde Madrid en el equipo global de Calidad de la Construcción de Vestas, el líder mundial en energía sostenible. Colaboro con colegas en los cinco continentes para crear herramientas basadas en datos que faciliten el seguimiento y mejora continua de la calidad de nuestros aerogeneradores y, con ello, contribuir a acelerar la transición energética.\nQue mi rol tenga impacto tangible y que la misión de mi organización contribuya a resolver problemas que realmente importan son mis dos no negociables.\nMi experiencia incluye:\nAnálisis de datos operativos y en contextos de desarrollo. Visualización de datos en tiempo real (Power BI) y estáticos (R, Python) Comunicación de insights complejos en lenguaje entendible por audiencias técnicas y no técnicas, porque creo firmemente que hablar \u0026ldquo;en sencillo\u0026rdquo; es una forma de democratizar el conocimiento. Investigación cuantitativa y cualitativa. R, Python, Power BI, SQL, Excel y QGIS. ","date":"4 febrero 2025","externalUrl":null,"permalink":"/acerca-de/","section":"","summary":"Mi carrera comenzó en Perú, en investigación académica y proyectos de desarrollo, trabajando con personas y organizaciones que buscaban generar cambio real. Fue ahí donde descubrí que el problema rara vez era la falta de datos, sino saber cómo convertirlos en información y conocimiento.\n","title":"Acerca de","type":"page"},{"content":"","date":"2 enero 2025","externalUrl":null,"permalink":"/tags/f%C3%BAtbol/","section":"Tags","summary":"","title":"Fútbol","type":"tags"},{"content":"","date":"2 enero 2025","externalUrl":null,"permalink":"/tags/python/","section":"Tags","summary":"","title":"Python","type":"tags"},{"content":"","date":"2 enero 2025","externalUrl":null,"permalink":"/tags/web-scraping/","section":"Tags","summary":"","title":"Web Scraping","type":"tags"},{"content":"\rEn este post explicaré cómo construí un scraper en Python para recolectar las estadísticas de los jugadores de la Euro 2024 desde la web oficial de la UEFA.\n¿Por qué?\r#\rEntre junio y julio del 2024 tuvo lugar la EURO 2024. En ese contexto, participé de un reto del chapter local de Omdena en Tunisia: UEFA EURO 2024 - Leveraging Machine Learning and Open Data Sets for Advanced Sports Analytics. El propósito era analizar este evento en lo deportivo y lo económico. Si bien nos quedamos cortos en este último aspecto, fue un espacio interesante para aplicar técnicas de ciencia de datos al mundo del fútbol.\nAsí, varios colegas se dispusieron a buscar datasets ya existentes: estadísticas de cada partido, datasets históricos o lo que haya. Cuando visité la página de la EURO, vi que era posible scrapearla para generar un dataset.\nA modo de documentación de ese ejercicio, en este post resumo la lógica detrás del scraper en Python + Selenium que hice y que extrae las estadísticas de jugadores desde la web de la UEFA y las prepara en un pandas.DataFrame para análisis exploratorio y modelado.\nResumen técnico\r#\rEl objetivo principal es automatizar la recolección de datos de los jugadores de la EURO a falta de acceso a una API oficial. El output debía ser un dataset en formato tabular.\nUsé Python por ser el lenguaje de preferencia en los proyectos de Omdena en los que he participado, aunque también R hubiera servido. La librería principal fue Selenium, que permite controlar el navegador web (en mi caso, Chrome) para interactuar con páginas dinámicas que cargan contenido vía JavaScript.\nHacia los meses que hice este scraper, los términos y condiciones de la web de la UEFA permitían el web scraping para fines no comerciales. Recomiendo revisar los términos actuales antes de ejecutar cualquier scraper.\nPasos\r#\rEl scraper, que es open source, está disponible en GitHub:\ncastellco/euro_2024_scraper\rGetting the game statistics of EURO 2024 players with Python and Selenium\rJupyter Notebook\r0\r0\rLas condiciones previas son tener conexión a internet, Python 3.8+ instalado y las librerías necesarias (ver requirements.txt en el repo).\nBásicamente, los pasos para ejecutarlo son:\nPreparar del entorno\r#\rPrimero se importan las librerías necesarias e instala el driver de Chrome automáticamente con webdriver_manager. Luego, se configuran las opciones del navegador Chrome (p. ej. --start-maximized). Esto es para que se ejecute Chrome en modo gráfico y no headless —ya que algunas tablas no cargan bien en modo headless— y también por una preferencia personal: prefiero ver lo que hace el scraper en tiempo real.\n# 1: import libraries ----------------------------------------------------- import time from selenium import webdriver from selenium.webdriver.chrome.service import Service from webdriver_manager.chrome import ChromeDriverManager from selenium.webdriver.common.by import By from selenium.webdriver import ActionChains import pandas as pd import re chrome_options = webdriver.ChromeOptions() chrome_options.add_argument(\u0026#34;--start-maximized\u0026#34;)\rAbrir la web y preparar la página\r#\rPosteriormente, se instala e inicia el webdriver.Chrome(...) y se carga la página https://www.uefa.com/european-qualifiers/statistics/players/.\n# 2: enter website, reject cookies and define function to scroll ---------- driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options) driver.get(\u0026#34;https://www.uefa.com/european-qualifiers/statistics/players/\u0026#34;)\rEsperamos 2 segundos. Como se podrá apreciar, a lo largo del script usé varias pausas con time.sleep() para dar tiempo a que la página cargue dinámicamente y para, en teoría, evitar bloqueos por parte del servidor web. Luego, para indicarle a Selenium qué lugar de la página clickear para rechazar las cookies, uso un CSS selector que apunta al botón de cookies ya que no me fue posible identificar el XPath.\nEn este punto, es importante comentar que para identificar CSS selectors, la extensión de Chrome SelectorGadget siempre me ha parecido excelente.\nRechazadas ya las cookies, definí la función scroll_to_sponsors() para desplazar la página hacia abajo y con ello forzar la carga completa de la tabla dinámica de jugadores. En específico, esta función busca el banner de sponsors (que en ese entonces estaba al final de la página) usando su XPath y desplaza la vista hasta ese elemento. Esto es necesario porque la tabla de jugadores carga más filas a medida que se hace scroll hacia abajo. Necesitaba tener toda la tabla cargada.\n# define function to scroll down, in order to make rest of the table discoverable def scroll_to_sponsors(): try: sponsors_xpath = \u0026#34;//div[contains(text(), \u0026#39;Official global sponsors\u0026#39;)]\u0026#34; select_sponsors_banner = driver.find_element(By.XPATH, sponsors_xpath) ActionChains(driver)\\ .scroll_to_element(select_sponsors_banner)\\ .perform() time.sleep(2) except: try: sponsors_xpath = \u0026#39;//div[@class=\u0026#34;pk-container pk-bg--background lazyloaded\u0026#34; and @role=\u0026#34;region\u0026#34; and @pk-theme=\u0026#34;light\u0026#34; and @aria-label=\u0026#34;\u0026#34;]\u0026#39; select_sponsors_banner = driver.find_element(By.XPATH, sponsors_xpath) ActionChains(driver)\\ .scroll_to_element(select_sponsors_banner)\\ .perform() time.sleep(2) except: print(\u0026#34;The scroll_to_sponsors function didn\u0026#39;t work.\u0026#34;) time.sleep(2)\rTambién creé un dataset vacío con pandas.DataFrame() y varias listas vacías para almacenar los datos de cada jugador mientras se itera sobre ellos.\n# will need these later: dataset = pd.DataFrame() name, national_team, club, overview_figures, overview_labels, stats_figures, stats_labels = [], [], [], [], [], [], []\rDefinir funciones auxiliares de extracción\r#\rLuego, definí varias funciones auxiliares para extraer datos específicos de la página. Esta parte fue la que, de lejos, me demandó más tiempo y esfuerzo. Fue prueba y error. Recozco que hay muchas cosas mejorables, pero el objetivo era tener un scraper funcional en un tiempo razonable.\nLa primera función, extract_name_and_teams(), extrae el nombre completo del jugador, su selección nacional y su club actual. Usé varios try/except para manejar casos donde algún dato no esté disponible o el selector falle.Nuevamente usé CSS selectors y XPath para localizar los elementos gracias a la extensión SelectorGadget.\nLa función extract_list_with_xpath(labels_xpath) toma un XPath como argumento y devuelve una lista de textos de los elementos que coinciden con ese XPath. Esto se usa para extraer tanto las etiquetas como las cifras de las secciones de \u0026ldquo;overview\u0026rdquo; y \u0026ldquo;statistics\u0026rdquo;.\nopen_accordions es una función que abre las secciones colapsables (acordeones) en la pestaña de estadísticas del jugador para asegurarse de que todos los datos estén visibles y accesibles para la extracción.\nFinalmente, update_dataset(dataset) toma el dataset actual y agrega una nueva fila con los datos del jugador actual. Esta función maneja la normalización de columnas entre distintos jugadores, evitando duplicados y asegurando que todas las filas tengan las mismas columnas, incluso si algunos jugadores no tienen ciertos datos. Esta función es mejorable por los tantos if/elif anidados, pero en el momento sirvió para el propósito. Un punto de mejora es simplificar los casos en los que ciertos jugadores tienen más o menos columnas que otros.\n# 3: define main functions ------------------------------------------------ def extract_name_and_teams(): try: name = driver.find_element(By.CSS_SELECTOR, \u0026#39;.player-header__name--first\u0026#39;).text + \u0026#39; \u0026#39; + driver.find_element(By.CSS_SELECTOR, \u0026#39;.player-header__name--last\u0026#39;).text print(name) except: print(\u0026#39;Player name and/or last name not found.\u0026#39;) try: # national_team = driver.find_element(By.CSS_SELECTOR, \u0026#39;.player-header__teams \u0026gt; div:nth-child(1) \u0026gt; a:nth-child(3) \u0026gt; pk-identifier:nth-child(1) \u0026gt; div:nth-child(2) \u0026gt; span:nth-child(1)\u0026#39;).text # print(national_team) national_team = driver.find_element(By.XPATH, \u0026#39;//span[@class=\u0026#34;player-header__team-name pk-text--text-01\u0026#34;][1]\u0026#39;).text print(national_team) except: print(\u0026#39;National team not found.\u0026#39;) try: club = driver.find_element(By.CSS_SELECTOR, \u0026#39;.player-header__teams \u0026gt; div:nth-child(2) \u0026gt; a:nth-child(3) \u0026gt; pk-identifier:nth-child(1) \u0026gt; div:nth-child(2) \u0026gt; span:nth-child(1)\u0026#39;).text print(club) except: try: print(\u0026#39;Club not found. Trying another xpath...\u0026#39;) club = driver.find_element(By.XPATH, \u0026#39;/html/body/div[3]/div/div/div[2]/div[3]/div[2]/div[2]/pk-identifier/div/div[1]/div[2]/pk-identifier/div/span\u0026#39;).text print(club) except: print(\u0026#39;Club not found.\u0026#39;) club = \u0026#34;\u0026#34; return name, national_team, club def extract_list_with_xpath(labels_xpath): if driver.find_elements(By.XPATH, \u0026#34;//h2[contains(text(), \u0026#39;Qualifying stats\u0026#39;)]\u0026#34;): labels_text = [] print(\u0026#39;Player only participated in qualifyings.\u0026#39;) else: all_labels = driver.find_elements(By.XPATH, labels_xpath) labels_text = [label.text for label in all_labels] return labels_text def open_accordions(): for i in range(0, 6): try: driver.find_element(By.CSS_SELECTOR, \u0026#39;#accordion-item-\u0026#39; + str(i) + \u0026#39; \u0026gt; pk-accordion-item-title:nth-child(1) \u0026gt; h2:nth-child(1)\u0026#39;).click() time.sleep(2) except: print(\u0026#39;There are no more accordions to open.\u0026#39;) def update_dataset(dataset): player_info = [name, national_team, club] + overview_figures if stats_figures: player_info += stats_figures else: player_info += [\u0026#34;\u0026#34;] * len(stats_figures) if stats_labels: columns = [\u0026#34;name\u0026#34;, \u0026#34;national_team\u0026#34;, \u0026#34;club\u0026#34;] + overview_labels + stats_labels else: columns = [\u0026#34;name\u0026#34;, \u0026#34;national_team\u0026#34;, \u0026#34;club\u0026#34;] + overview_labels new_row = pd.DataFrame([player_info], columns=columns) new_row = new_row.loc[:,~new_row.columns.duplicated()].copy() dataset = dataset.loc[:,~dataset.columns.duplicated()].copy() if dataset.empty: print(\u0026#34;Condition met: dataset.empty\u0026#34;) elif len(dataset.columns) == len(columns): print(\u0026#34;Condition met: len(dataset.columns) == len(columns)\u0026#34;) try: dataset = dataset[columns] except: print(\u0026#39;Something went wrong when executing the if statement of the len(dataset.columns) == len(columns) condition in case of \u0026#39; + name + \u0026#39; from \u0026#39; + national_team) elif len(dataset.columns) \u0026lt; len(columns): print(\u0026#34;Condition met: len(dataset.columns) \u0026lt; len(columns)\u0026#34;) try: for column in columns: if column not in dataset.columns: dataset[column] = \u0026#34;\u0026#34; else: continue dataset = dataset[new_row.columns] except: print(\u0026#39;Something went wrong when executing the if statement of the len(dataset.columns) \u0026lt; len(columns) condition in case of \u0026#39; + name + \u0026#39; from \u0026#39; + national_team) elif len(dataset.columns) \u0026gt; len(columns): print(\u0026#34;Condition met: len(dataset.columns) \u0026gt; len(columns)\u0026#34;) try: for column in dataset.columns: if column not in columns: new_row[column] = \u0026#34;\u0026#34; else: continue new_row = new_row[dataset.columns] except: print(\u0026#39;Something went wrong when executing the if statement of the len(dataset.columns) \u0026gt; len(columns) condition in case of \u0026#39; + name + \u0026#39; from \u0026#39; + national_team) else: print(\u0026#39;Something went wrong when executing update_dataset function.\u0026#39;) dataset = pd.concat([dataset, new_row], ignore_index=True) return dataset\rEjecución del scraper\r#\rAhora, se ejecuta el scraper. Este es el paso que demora más, ya que hay muchos países y jugadores, y por los tiempos de espera que añadí por las razones que comenté párrafos arriba.\nLa lógica es iterar sobre cada país participante (del 2 al 54 en el acordeón de selección de países) y luego sobre cada jugador listado para ese país. Para próximaas ediciones, el range podría cambiar.\nPor cada jugador, se extraen los datos usando las funciones definidas previamente y se actualiza el dataset.\n# 4: scraping work: iterate over each country and each player ------------- for i in range(2, 55): # open main site driver.get(\u0026#34;https://www.uefa.com/european-qualifiers/statistics/players/\u0026#34;) # select main tournament (excluding qualiying) time.sleep(2) try: main_tournament = driver.find_element(By.XPATH, \u0026#39;//pk-accordion-item[1]/pk-accordion-item-content/pk-radio/pk-radio-option[1]\u0026#39;) time.sleep(2) main_tournament.click() time.sleep(2) except: main_tournament = driver.find_element(By.XPATH, \u0026#39;//input[@class=\u0026#34;pk-radio\u0026#34; and @name=\u0026#34;phase\u0026#34; and @title=\u0026#34;phase\u0026#34; and @type=\u0026#34;radio\u0026#34; and @id=\u0026#34;tournament\u0026#34; and @value=\u0026#34;TOURNAMENT\u0026#34; and @part=\u0026#34;input\u0026#34;]\u0026#39;) time.sleep(2) main_tournament.click() time.sleep(2) # select country xpath_country = \u0026#39;//pk-accordion-item[2]/pk-accordion-item-content/div/pk-radio/pk-radio-option[\u0026#39; + str(i) + \u0026#39;]/span\u0026#39; select_country = driver.find_element(By.XPATH, xpath_country) country_name = select_country.text print(\u0026#39;---------- Accessing info of \u0026#39; + country_name + \u0026#39; ----------\u0026#39;) time.sleep(2) select_country.click() # select country time.sleep(3) # scroll down twice, as needed to discover the whole page scroll_to_sponsors() scroll_to_sponsors() # gather all players\u0026#39; stats website links try: player_xpath = \u0026#39;//a[contains(@class, \u0026#34;pk-w--100\u0026#34;) and contains(@href, \u0026#34;/api/v1/linkrules/player/\u0026#34;) and contains(@href, \u0026#34;/statistics?competitionId=3\u0026amp;phase=TOURNAMENT\u0026#34;)]\u0026#39; select_player = driver.find_elements(By.XPATH, player_xpath) except: print(\u0026#39;Seems like the site of \u0026#39; + country_name + \u0026#39; is empty.\u0026#39;) continue players_ids = [] for link in select_player: href = link.get_attribute(\u0026#39;href\u0026#39;) player_id = re.search(r\u0026#39;player/(\\d+)/\u0026#39;, href).group(1) players_ids.append(player_id) for player_id in players_ids: time.sleep(2) driver.get(\u0026#39;https://www.uefa.com/euro2024/teams/players/\u0026#39; + player_id + \u0026#39;/\u0026#39;) print(\u0026#39;---------- Working on player whose ID is \u0026#39; + player_id + \u0026#39; -------------\u0026#39;) time.sleep(2) name, national_team, club = extract_name_and_teams() overview_labels = extract_list_with_xpath(\u0026#39;//span[@class=\u0026#34;player-profile-category\u0026#34;]\u0026#39;) overview_figures = extract_list_with_xpath(\u0026#39;//span[@class=\u0026#34;player-profile-value\u0026#34;]\u0026#39;) print(overview_labels) print(overview_figures) time.sleep(2) driver.get(\u0026#39;https://www.uefa.com/euro2024/teams/players/\u0026#39; + player_id + \u0026#39;/statistics/\u0026#39;) time.sleep(2) scroll_to_sponsors() open_accordions() stats_labels = extract_list_with_xpath(\u0026#39;//div[@slot=\u0026#34;stat-label\u0026#34;]\u0026#39;) stats_figures = extract_list_with_xpath(\u0026#39;//div[@slot=\u0026#34;stat-value\u0026#34;]\u0026#39;) print(stats_labels) print(stats_figures) dataset = update_dataset(dataset) print(\u0026#39;---------- End of process for player whose ID is \u0026#39; + player_id + \u0026#39; ----------\u0026#39;) time.sleep(2)\rConclusión\r#\rAl final de esta sección, se obtiene un dataset: una tabla de 621x66 que puede ser usada para diversos análisis de performance en el campo. Si bien es cierto que hay espacio de mejora en el código, el scraper cumplió su propósito y permitió recolectar datos valiosos para el reto de Omdena. Además, más allá de todo, fue una buena excusa para practicar web scraping y Python, ya que mi herramienta por defecto suele ser R.\nEl dataset publicado está en el repo en GitHub y Dagshub.\n","date":"2 enero 2025","externalUrl":null,"permalink":"/posts/euro-2024-scraper/","section":"Posts","summary":"Aquí repaso cómo hice un script de web scraping en Python para recolectar las estadísticas de los jugadores de la Euro 2024.","title":"Web Scraping con Python: La Euro 2024","type":"posts"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"}]